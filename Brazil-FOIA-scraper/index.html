<!doctype html>
<html>
  <head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">
    <title class=title>Scraping Brazil's FOIA requests</title>
  </head>
  <div class=container>
  <body>
    <section class="hero is-warning">
      <div class="hero-body">
        <p class="title">
          Scraping Brazil's Freedom of Informaction Act (FOIA) requests
        </p>
        <p class="subtitle">
          These scrapers were built in Python/Selenium
        </p>
      </div>
    </section>

    <section class="section">
    <p>They save all FOIA requests (Freedom of Information Act or Lei de Acesso à Informação in Portuguese) sent by Brazilian citizens in a spreadsheet based on a specific keyword. The first scraper, "Raspador de decisões da CGU com o termo LGPD no texto.ipynb", creates a spreadsheet containing all those FOIA requests that were denied by the federal government because of alleged sensitive/personal information. The second scraper, "pedidos_sobre_Bolsonaro_no_FALABR.ipynb", creates a spreadsheet containing all FOIA requests and answers for those requests in the last 30 days (it is possible to change the time) for a specific keyword. This scraper was built as part of a introduction to programming class at the <a target="_new"href="https://journalism.columbia.edu/ms-data-journalism"> Columbia University - Master of Science in Data Journalism </a></p></p>
   
<br>
    <a class="button is-warning"
    href="https://github.com/luizftoledo/FOIA-scrapers-in-Brazil/blob/main/Final%20project%20-%20Scraping%20FOIA%20(Access%20to%20information)%20requests%2C%20responses%2C%20denials%20and%20appeals%20in%20Brazil.pdf">Read a detailed presentation
    here</a>
    <a class="button is-success"
    href="https://github.com/luizftoledo/FOIA-scrapers-in-Brazil">Read the code
    here</a>
  </section>
  </div>
  </body>
</html>





